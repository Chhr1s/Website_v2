---
title: Growth & Parallel Process Models
author: Christopher Loan
date: '2020-09-08'
slug: growth-parallel-process-models
categories:
  - Structural Equation Modeling
tags:
  - SEM
  - Structural Equation Modeling
description: ''
topics: []
---



<div id="introduction" class="section level1">
<h1>Introduction:</h1>
<p>The first project I worked on in graduate school was doing secondary data analysis on a six-wave longitudinal study. I developed some research questions and dove in, looking at changes from one wave to the next. Quickly, though, I began expressing questions about the growth and change of dynamic factors that I couldn’t answer with the methods I knew. 
My advisor directed me towards structural equation modeling—as this was her background—with focus on growth models. At first I felt unable to pursue these methods with the price point of the software that she used for SEM, untitl I found <code>{lavaan}</code>. 
I had to do a <em>lot</em> of reading to figure out how to get versed in both SEM and the package, so I wanted to share a lavaan-specific tutorial in such methods here.
This project will look at growth of two factors over time, as most of the tutorials I have found explain only one factor (e.g., <a href="https://lavaan.ugent.be/tutorial/growth.html">the growth curve page on the <code>lavaan</code> website</a>) and putting two of these together can be daunting to a new <code>R</code> or <code>lavaan</code> user.
Think of this more as a tutorial of the steps needed to take when fitting growth models in <code>lavaan</code>, rather than a tutorial solely on either the method or the software.
As a quick terminology aside: I refer to growth models where 2+ factors are modeled “in parallel over time” as parallel process models (PPMs), but they are sometimes referred to differently. </p>
<div id="notes" class="section level4">
<h4>Notes:</h4>
<ol style="list-style-type: decimal">
<li><p>Being a SEM method, this assumes some familiarity with SEM, though I hope to present this in a way that is clear to as many people as possible.</p></li>
<li><p>I expect you to understand or to be able to refer to <a href="https://lavaan.ugent.be/tutorial/index.html"><code>lavaan</code> syntax</a> for basic syntax/interpretation.</p></li>
<li><p>Consider what I give you the nuts and bolts in how to make this work, and you should refer to other resources for more in depth interpretations.</p></li>
</ol>
</div>
</div>
<div id="simulating-data-for-demonstration" class="section level1">
<h1>Simulating Data for Demonstration</h1>
<p>In order to complete this project, I simulated some data (n = 500). For simplicity, I actually used <code>lavaan</code> to make my data, but other software can do this too. 
I am reserving the code for this until the end, in case you would like to know how I did that, or if you’re curious to see how closely our PPM approximates the structure of the data we made. 
Specifically, I made two variables across 4 waves (growth modeling assumes time to be equally spaced). 
I named the variables x1 = x at time 1, x2 = x at time 2, etc. &amp; y1 = y at time 1, etc.</p>
</div>
<div id="fit-statistics" class="section level1">
<h1>Fit statistics</h1>
<p>It’s good practice to have a set of fit statistcs specified <em>a priori</em> so you aren’t cherry picking good and bad results. Here’s a spread of them I’ve selected:</p>
<pre class="r"><code>selected_fit_stats &lt;-   c(&quot;chisq.scaled&quot;,
                         &quot;df.scaled&quot;,
                         &quot;pvalue.scaled&quot;, ## ideally n.s.
                         &quot;cfi.scaled&quot;, ## ideally ≥ 0.95
                         &quot;rmsea.scaled&quot;, ## ideally ≤ 0.05
                         &quot;rmsea.pvalue.scaled&quot;, ## ideally n.s.
                         &quot;srmr&quot; ## ideally &lt; 0.08
                         )</code></pre>
</div>
<div id="steps-for-a-ppm" class="section level1">
<h1>Steps for a PPM:</h1>
<ol style="list-style-type: decimal">
<li>Assess fit of various models with different functional forms (i.e., no growth, linear growth, quadratic growth, etc.).</li>
<li>Compare the fit of nested models.</li>
<li>Repeat</li>
</ol>
<p>You can calculate fit on models where the highest term is x^(n-2)</p>
<p>Time to first fit the model to an intercept-only model (i.e., no growth observed), then look at linear growth (linear + intercept), then quadratic growth (quadratic + linear + intercept).</p>
<pre class="r"><code>int_x_mod &lt;- 
  &#39;
iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4

  &#39;
int_x_fit &lt;- growth(model = int_x_mod,
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat,
                     meanstructure = T)</code></pre>
<pre><code>## Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov
## variances are negative</code></pre>
<pre class="r"><code>int_x_fit_stats&lt;-fitmeasures(int_x_fit, selected_fit_stats) %&gt;% data.frame()
int_x_fit_stats</code></pre>
<pre><code>##                                .
## chisq.scaled        2064.3493976
## df.scaled              8.0000000
## pvalue.scaled          0.0000000
## cfi.scaled             0.0000000
## rmsea.scaled           0.7169988
## rmsea.pvalue.scaled    0.0000000
## srmr                   1.5574880</code></pre>
<pre class="r"><code>int_y_mod &lt;- 
  &#39;
iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
  &#39;
int_y_fit &lt;- growth(model = int_y_mod, 
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat,
                     meanstructure = T)</code></pre>
<pre><code>## Warning in lav_object_post_check(object): lavaan WARNING: some estimated lv
## variances are negative</code></pre>
<pre class="r"><code>int_y_fit_stats&lt;-fitmeasures(int_y_fit, selected_fit_stats) %&gt;% data.frame()
int_y_fit_stats</code></pre>
<pre><code>##                                .
## chisq.scaled        3671.5381788
## df.scaled              8.0000000
## pvalue.scaled          0.0000000
## cfi.scaled             0.0000000
## rmsea.scaled           0.9570186
## rmsea.pvalue.scaled    0.0000000
## srmr                   1.9360811</code></pre>
<p>Neither of those fit well, so we can add a higher-order fit term. Specifically, we will check how well a linear-only growth model fits for the <code>{x}</code> &amp; <code>{y}</code> variables</p>
<pre class="r"><code>linear_x_mod &lt;- 
  &#39;
iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4
sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4

  &#39;
linear_x_fit &lt;- growth(model = linear_x_mod,
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat,
                     meanstructure = T)

linear_x_fit_stats&lt;-fitmeasures(linear_x_fit, selected_fit_stats) %&gt;% data.frame()
linear_x_fit_stats</code></pre>
<pre><code>##                              .
## chisq.scaled        5.49443372
## df.scaled           5.00000000
## pvalue.scaled       0.35855663
## cfi.scaled          0.99969401
## rmsea.scaled        0.01406320
## rmsea.pvalue.scaled 0.84594503
## srmr                0.01561116</code></pre>
<pre class="r"><code>linear_y_mod &lt;- 
  &#39;
iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4
  &#39;
linear_y_fit &lt;- growth(model = linear_y_mod,
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat,
                     meanstructure = T)</code></pre>
<pre><code>## Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov
## variances are negative</code></pre>
<pre><code>## Warning in lav_object_post_check(object): lavaan WARNING: some estimated lv
## variances are negative</code></pre>
<pre class="r"><code>linear_y_fit_stats&lt;-fitmeasures(linear_y_fit, selected_fit_stats) %&gt;% data.frame()
linear_y_fit_stats</code></pre>
<pre><code>##                                .
## chisq.scaled        1181.3526239
## df.scaled              5.0000000
## pvalue.scaled          0.0000000
## cfi.scaled             0.2720970
## rmsea.scaled           0.6859599
## rmsea.pvalue.scaled    0.0000000
## srmr                   1.2678251</code></pre>
<p>Looks like the linear <code>{x}</code> fits very well, but not <code>{y}</code>. We should check if the quadratic growth models fit well. We’ll do both variables, in case a quadratic model fits the <code>{x}</code> better than the linear model for <code>{x}</code>.</p>
<p>As a note: Quadratic terms represent the rate of change of the slope on average across the waves. This is synonymous with acceleration, though this terminology is not often used; ‘quadratic growth’ is typically preferred</p>
<pre class="r"><code>quad_x_mod &lt;- 
  &#39;
iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4
sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4
qX =~ 0*x1 + 1*x2 + 4*x3 + 9*x4


  &#39;
quad_x_fit &lt;- growth(model = quad_x_mod, 
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat,
                     meanstructure = T)

quad_x_fit_stats &lt;- fitmeasures(quad_x_fit, selected_fit_stats)
quad_x_fit_stats</code></pre>
<pre><code>##        chisq.scaled           df.scaled       pvalue.scaled          cfi.scaled 
##               0.429               1.000               0.512               1.000 
##        rmsea.scaled rmsea.pvalue.scaled                srmr 
##               0.000               0.717               0.003</code></pre>
<pre class="r"><code>quad_y_mod &lt;- 
  &#39;
iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4
qY =~ 0*y1 + 1*y2 + 4*y3 + 9*y4


  &#39;
quad_y_fit &lt;- growth(model = quad_y_mod, 
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat,
                     meanstructure = T)

quad_y_fit_stats &lt;- fitmeasures(quad_y_fit, selected_fit_stats)
quad_y_fit_stats</code></pre>
<pre><code>##        chisq.scaled           df.scaled       pvalue.scaled          cfi.scaled 
##               0.007               1.000               0.932               1.000 
##        rmsea.scaled rmsea.pvalue.scaled                srmr 
##               0.000               0.963               0.000</code></pre>
<p>It’s clear that only the <code>{x}</code> linear model was a good one by all fit statistics. When using real—world data—rather than data simulated to be specific functional forms—this may or may not be the case. If that’s the case, there are resources about comparing models. One popular way is through likelihood-ratio tests or chi-square difference tests.</p>
</div>
<div id="parallel-process-model" class="section level1">
<h1>Parallel process model</h1>
<p>Now that we are fairly confident in functional forms, let’s model them together</p>
<pre class="r"><code>full_model &lt;- 
  &#39;
## intercept &amp; slope growth terms for X
iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4
sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4

## intercept, slope, &amp; quadratic terms for Y
iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4
qY =~ 0*y1 + 1*y2 + 4*y3 + 9*y4

sX ~ a1*iX + iY
sY ~ iX + a2*iY
qY ~ a3*sY + sX + iX + iY 

sY ~~ sX
iY ~~ iX

outcome ~ iX + b1*sX + iY + b2*sY + b3*qY

iX_sX_outcome := a1*b1
iY_sY_outcome := a2*b2
sY_qY_outcome := a3*b3
  &#39;

full_fit &lt;- growth(model = full_model, 
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat,
                     meanstructure = T)
full_fit_stats &lt;- fitmeasures(full_fit, selected_fit_stats)</code></pre>
</div>
<div id="full-model-fit" class="section level1">
<h1>Full Model Fit</h1>
<p>We can see that this model fits well across all fit statistics chosen. This model is deemed acceptable and we can now interpret the model results</p>
<pre class="r"><code>summary(full_fit,
        stand = T,
        rsq = T)</code></pre>
<pre><code>## lavaan 0.6-7.1577 ended normally after 100 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of free parameters                         34
##                                                       
##   Number of observations                           500
##                                                       
## Model Test User Model:
##                                                Standard      Robust
##   Test Statistic                                 15.848      15.978
##   Degrees of freedom                                 20          20
##   P-value (Chi-square)                            0.726       0.718
##   Scaling correction factor                                   0.992
##        Yuan-Bentler correction (Mplus variant)                     
## 
## Parameter Estimates:
## 
##   Standard errors                             Sandwich
##   Information bread                           Observed
##   Observed information based on                Hessian
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   iX =~                                                                 
##     x1                1.000                               1.049    0.725
##     x2                1.000                               1.049    0.494
##     x3                1.000                               1.049    0.345
##     x4                1.000                               1.049    0.255
##   sX =~                                                                 
##     x1                0.000                               0.000    0.000
##     x2                1.000                               1.121    0.528
##     x3                2.000                               2.242    0.738
##     x4                3.000                               3.363    0.817
##   iY =~                                                                 
##     y1                1.000                               1.073    0.736
##     y2                1.000                               1.073    0.579
##     y3                1.000                               1.073    0.235
##     y4                1.000                               1.073    0.111
##   sY =~                                                                 
##     y1                0.000                               0.000    0.000
##     y2                1.000                               1.183    0.638
##     y3                2.000                               2.366    0.517
##     y4                3.000                               3.548    0.368
##   qY =~                                                                 
##     y1                0.000                               0.000    0.000
##     y2                1.000                               1.080    0.583
##     y3                4.000                               4.321    0.944
##     y4                9.000                               9.722    1.008
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   sX ~                                                                  
##     iX        (a1)    0.511    0.096    5.341    0.000    0.479    0.479
##     iY                0.061    0.069    0.883    0.377    0.059    0.059
##   sY ~                                                                  
##     iX                0.038    0.091    0.416    0.677    0.034    0.034
##     iY        (a2)   -0.328    0.114   -2.878    0.004   -0.297   -0.297
##   qY ~                                                                  
##     sY        (a3)   -0.199    0.107   -1.866    0.062   -0.218   -0.218
##     sX                0.040    0.064    0.625    0.532    0.041    0.041
##     iX                0.017    0.078    0.217    0.828    0.016    0.016
##     iY               -0.033    0.062   -0.526    0.599   -0.032   -0.032
##   outcome ~                                                             
##     iX                0.114    0.281    0.404    0.686    0.119    0.027
##     sX        (b1)    1.913    0.232    8.243    0.000    2.145    0.492
##     iY                0.233    0.241    0.967    0.334    0.250    0.057
##     sY        (b2)    2.580    0.366    7.056    0.000    3.051    0.700
##     qY        (b3)    1.585    0.232    6.828    0.000    1.712    0.393
## 
## Covariances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##  .sX ~~                                                                 
##    .sY               -0.062    0.107   -0.579    0.563   -0.056   -0.056
##   iX ~~                                                                 
##     iY                0.073    0.084    0.874    0.382    0.065    0.065
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .x1                0.000                               0.000    0.000
##    .x2                0.000                               0.000    0.000
##    .x3                0.000                               0.000    0.000
##    .x4                0.000                               0.000    0.000
##    .y1                0.000                               0.000    0.000
##    .y2                0.000                               0.000    0.000
##    .y3                0.000                               0.000    0.000
##    .y4                0.000                               0.000    0.000
##    .outcome           0.000                               0.000    0.000
##     iX                2.007    0.060   33.474    0.000    1.913    1.913
##    .sX                0.817    0.225    3.625    0.000    0.729    0.729
##     iY                1.967    0.064   30.833    0.000    1.832    1.832
##    .sY               -0.758    0.237   -3.195    0.001   -0.641   -0.641
##    .qY               -2.389    0.196  -12.202    0.000   -2.211   -2.211
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .x1                0.992    0.112    8.825    0.000    0.992    0.474
##    .x2                1.023    0.079   12.932    0.000    1.023    0.227
##    .x3                0.826    0.089    9.281    0.000    0.826    0.090
##    .x4                1.115    0.185    6.011    0.000    1.115    0.066
##    .y1                0.972    0.164    5.915    0.000    0.972    0.458
##    .y2                0.917    0.100    9.123    0.000    0.917    0.267
##    .y3                0.972    0.231    4.207    0.000    0.972    0.046
##    .y4                0.728    1.563    0.466    0.642    0.728    0.008
##    .outcome           4.636    1.153    4.019    0.000    4.636    0.244
##     iX                1.100    0.122    9.053    0.000    1.000    1.000
##    .sX                0.960    0.127    7.582    0.000    0.764    0.764
##     iY                1.152    0.162    7.110    0.000    1.000    1.000
##    .sY                1.276    0.293    4.350    0.000    0.912    0.912
##    .qY                1.111    0.081   13.700    0.000    0.952    0.952
## 
## R-Square:
##                    Estimate
##     x1                0.526
##     x2                0.773
##     x3                0.910
##     x4                0.934
##     y1                0.542
##     y2                0.733
##     y3                0.954
##     y4                0.992
##     outcome           0.756
##     sX                0.236
##     sY                0.088
##     qY                0.048
## 
## Defined Parameters:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##     iX_sX_outcome     0.979    0.236    4.141    0.000    1.026    0.236
##     iY_sY_outcome    -0.845    0.259   -3.259    0.001   -0.907   -0.208
##     sY_qY_outcome    -0.315    0.208   -1.515    0.130   -0.373   -0.086</code></pre>
<pre class="r"><code># lavaanPlot(model = full_fit, coefs = T, stars = T,
#            covs = T)
# edge.label.cex = .6, what = &quot;std&quot;, whatLabels = &quot;std&quot;,
#          label.prop=0.9, edge.label.color = &quot;black&quot;, rotation = 1, #layout = &quot;circle&quot;,
#          equalizeManifests = FALSE, optimizeLatRes = TRUE, node.width = 1.5, 
#          edge.width = 0.5, shapeMan = &quot;rectangle&quot;, shapeLat = &quot;ellipse&quot;, intercepts = F, #structural = T,
#          shapeInt = &quot;triangle&quot;, sizeMan = 4, sizeInt = 2, sizeLat = 4, 
#          curve=2, unCol = &quot;#070b8c&quot;, title = T)
# title(&quot;Full Model&quot;)</code></pre>
</div>
<div id="direct-paths-regressions" class="section level1">
<h1>Direct Paths / Regressions</h1>
<p>The model shows that the variable <code>{outcome}</code> is predicted significantly by linear slopes of both <code>{x}</code> and <code>{y}</code> (i.e., <code>{sX}</code> &amp; <code>{sY}</code>), as well as the <code>{qY}</code>. Baseline levels of both variables (<code>{iX}</code> &amp; <code>{iY}</code>) did not significantly predict the outcome. </p>
<p>We observed a significant indirect effect from baseline <code>{iX}</code> through <code>{sX}</code> to the <code>{outcome}</code>, which is likely why we do not see a direct effect of <code>{iX}</code> on the <code>{outcome}</code>. The same process is observed in <code>{Y}</code>. There was no indirect effect from <code>{sY}</code> to <code>{qY}</code> on <code>{outcome}</code></p>
<div id="covariances" class="section level3">
<h3>Covariances</h3>
<p>[ADD MATERIAL]</p>
</div>
<div id="means-intercepts" class="section level3">
<h3>Means / Intercepts</h3>
</div>
</div>
<div id="bootstrapping" class="section level1">
<h1>Bootstrapping</h1>
<p>Bootstrapping is a resampling method (with replacement) that is appreciated for building confidence intervals around parameter estimates of indirect effects, at least in part, because they do not make distributional assumptions about the indirect effect. This creates a more reliable test than standard significance tests. A quick Google Scholar search can inform you on this topic better than I can, but I used this to test the indirect effects using 5000 simulated data sets.</p>
<pre class="r"><code>final_fit_boot&lt;- growth(full_fit, data = sim_growth_dat, estimator = &quot;ML&quot;,
                        meanstructure = T,
                        se = &quot;bootstrap&quot;,
                        bootstrap = 5000,
                        parallel = &quot;multicore&quot;)

parameterEstimates(final_fit_boot,
                   level = .95,
                   boot.ci.type = &quot;bca.simple&quot;,
                   stand = T)[64:66,c(4,5,9,10)]</code></pre>
<pre><code>##            label    est ci.lower ci.upper
## 64 iX_sX_outcome  0.979    0.591    1.604
## 65 iY_sY_outcome -0.845   -1.335   -0.163
## 66 sY_qY_outcome -0.315   -0.680    0.098</code></pre>
<p>The model converged nearly every time without issue. Of our 5000 bootstrap draws, only 7 were not successful; this is not shown here, but is if you call <code>{summary(full_fit, fit.measures = T)}</code>, which I didn’t do for brevity. </p>
<p>Furthermore, we find the same results as we did regarding the indirect effect as without bootstrapping. These are the results I trust more, especially since we used the BCa simple variant used in <code>{lavaan}</code>. As a note, you should <em>not</em> trust the p-values from this parameterEstimates() if you go with anything but the default for <code>boot.ci.type =</code> if you use any <code>boot.ci.type</code> other than <code>norm</code>, as that is how the p-value is calculated. You can see a discussion between me &amp; the lavaan Google Group about this if you do some digging. It may be changed in the future, but is not of yet (to my knowledge). Simply report Confidence Intervals (95% in my case).</p>
</div>
<div id="plotting" class="section level1">
<h1>Plotting</h1>
<p>We can plot the growth of these traits, as well with <code>{ggplot2}</code> 
First we extract factor scores &amp; save this as a data frame, then we can plot.
For a linear model, this is pretty simple:</p>
<pre class="r"><code>plot_dat &lt;- lavPredict(full_fit) %&gt;% data.frame()

plot_X &lt;- ggplot(data=plot_dat) +
scale_x_continuous(name = &quot;Timepoint&quot;,
                 limits=c(0,3),
                 breaks = c(0, 1, 2, 3),
                 labels = c(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;)
                 ) +
scale_y_continuous(name = &quot;X&quot;,
                 limits=c(0,30)
                 )+
  geom_abline(data=plot_dat, 
              mapping=aes(slope=sX, 
                          intercept=iX), 
              color = &quot;lightblue&quot;) + 
  theme_minimal()
plot_X</code></pre>
<p><img src="/post/2020-09-08-growth-parallel-process-models_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>For a quadratic model, this is more challenging, but here’s some code to do it:</p>
<pre class="r"><code>plot_dat &lt;- lavPredict(full_fit) %&gt;% data.frame()

qY &lt;- plot_dat$qY
sY &lt;- plot_dat$sY
iY &lt;- plot_dat$iY

test &lt;- function(y) {qY*y ^ 2 + sY*y + iY}



nrow(plot_dat)</code></pre>
<pre><code>## [1] 500</code></pre>
<pre class="r"><code>plot_dat_2&lt;-data.frame(`T1` = test(0), 
                       `T2` = test(1), 
                       `T3` = test(2), 
                       `T4` = test(3), 
                       row.names = 1:nrow(plot_dat))

names(plot_dat) &lt;- c(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;) 

test0 &lt;-test(0)
test1&lt;-test(1)
test2&lt;-test(2)
test3&lt;-test(3)

Y_df &lt;- matrix(c(test0, 
                 test1, 
                 test2, 
                 test3), 
               ncol = 1)

df_long_wave &lt;- matrix(c(rep(1,500), 
                        rep(2, 500),
                        rep(3, 500), 
                        rep(4, 500)), 
                      ncol = 1)


plot_dat_2 &lt;- data.frame(id = matrix(
  rep(1:500,4), ncol = 1),
  Timepoint = df_long_wave,
  Y = Y_df)


plot_Y &lt;- plot_dat_2 %&gt;% ggplot(aes(x = Timepoint, 
                          y = Y, 
                          group = id)) +
 geom_smooth(formula = y ~ x + I(x^2), 
             method = &quot;lm&quot;, se = F)+
  theme_minimal() 

plot_Y</code></pre>
<p><img src="/post/2020-09-08-growth-parallel-process-models_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div id="looking-at-the-simulation-call" class="section level1">
<h1>Looking at the simulation call</h1>
<pre class="r"><code>growth_mod &lt;- 
  &#39;
## intercept &amp; slope growth terms for X
iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4
sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4

## intercept, slope, &amp; quadratic terms for Y
iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4
qY =~ 0*y1 + 1*y2 + 4*y3 + 9*y4

## (ignore this for now, we will come back to
## it during interpretation)

sX ~ 0.45*iX
sY ~ -0.2*iY

sY ~~ 1*sY
y4 ~~ 1.2*y4

outcome ~~ 3*outcome

iX + iY ~ 2*1
sX ~ 1*1
sY ~ -1*1
qY ~ -2*1

outcome ~ 0*iX + 0*iY + 2*sX + 3*sY + 1*qY

  &#39;</code></pre>
<p>In the data I simulated, Variable <code>{x}</code> is changing linearly over time and variable <code>{y}</code> is changing quadratically.</p>
<pre class="r"><code>sim_growth_dat &lt;- simulateData(model = growth_mod, 
                               model.type = &quot;growth&quot;, 
                               seed = 82020, 
                               orthogonal = F,
                               auto.cov.y = T, 
                               auto.var = T
                               )</code></pre>
</div>
