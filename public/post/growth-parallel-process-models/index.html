<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.74.3" />

  <title>Growth &amp; Parallel Process Models &middot; Christopher Loan</title>

    

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="/css/blackburn.css">

  
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.9.0/css/all.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon" />

  
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="/">CML</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="/post/"><i class='fa fa-list fa-fw'></i>Statistics</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="/education/"><i class='fa fa-school fa-fw'></i>Education</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="/contact/"><i class='fa fa-envelope fa-fw'></i>Contact</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://linkedin.com/in/https://www.linkedin.com/in/christopher-loan-09965950/" rel="me" target="_blank"><i class="fab fa-linkedin"></i></i>LinkedIn</a>
    </li>
    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/Chhr1s" rel="me" target="_blank"><i class="fab fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small>&copy; 2020. All rights reserved.</small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>Growth &amp; Parallel Process Models</h1>
  <h2></h2>
</div>
<div class="content">

  <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>September 08 2020, 12:00 am</time>
  </div>

  

  
  
  
  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="/tags/sem">SEM</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="/tags/structural-equation-modeling">Structural Equation Modeling</a>
    
  </div>
  
  

</div>

  


<div id="introduction" class="section level1">
<h1>Introduction:</h1>
<p>The first research project I worked on in graduate school was a secondary data analysis on a longitudinal study. I developed some research questions and dove in. I looked for wave-to-wave changes in various constructs of interest to me. Quickly, though, I began asking questions about the growth and change of dynamic factors that I couldn’t answer with the methods I knew. </p>
<p>One P.I. directed me towards structural equation modeling—as this was her background—with focus on growth models. At first I felt unable to pursue these methods with the price point of the software that she used for SEM, then I found <code>{lavaan}</code>. </p>
<p>I had to do a <em>lot</em> of reading to figure out how to get versed in both SEM and the package to answer these questions, so I wanted to share a <code>{lavaan}</code>-specific tutorial in such methods here.</p>
<p>This project will look at growth of two factors over time, as most of the tutorials I have found explain only one factor (e.g., <a href="https://lavaan.ugent.be/tutorial/growth.html">the growth curve page on the <code>{lavaan}</code> website</a>) and putting two of these together can be daunting to a new <code>{R}</code> or <code>{lavaan}</code> user.</p>
<p>Think of this more as a tutorial of the steps needed to take when fitting growth models in <code>{lavaan}</code>, rather than a tutorial solely on either the method or the software.</p>
<p>As a quick terminology aside: I refer to growth models where 2+ factors are modeled “in parallel over time” as parallel process models (PPMs), but they are sometimes referred to differently. </p>
<div id="notes" class="section level5">
<h5>NOTES:</h5>
<ol style="list-style-type: decimal">
<li><p>Being a SEM method, this assumes some familiarity with SEM, though I hope to present this in a way that is clear to as many people as possible.</p></li>
<li><p>I expect you to understand or to be able to refer to <a href="https://lavaan.ugent.be/tutorial/index.html"><code>{lavaan}</code> syntax</a> for basic syntax/interpretation.</p></li>
<li><p>Consider what I give you the nuts and bolts in how to make this work, and you should refer to other resources for more in depth interpretations.</p></li>
</ol>
<pre class="r"><code>library(lavaan)
library(ggplot2)
library(tidyverse)</code></pre>
</div>
</div>
<div id="simulating-data-for-demonstration" class="section level1">
<h1>Simulating Data for Demonstration</h1>
<p>In order to complete this project, I simulated some data (n = 500). For simplicity, I actually used <code>{lavaan}</code> to make my data, but other software can do this too. 
I am reserving the code for this until the end, in case you would like to know how I did that, or if you’re curious to see how closely our PPM approximates the structure of the data we made. 
Specifically, I made two variables across 4 waves (growth modeling assumes time to be equally spaced). 
I named the variables <code>{x1}</code> =<code>{x}</code>at time 1, <code>{x2}</code> = <code>{x}</code> at time 2, etc. &amp; <code>{y1}</code> = <code>{y}</code> at time 1, etc.</p>
</div>
<div id="fit-statistics" class="section level1">
<h1>Fit statistics</h1>
<p>In SEM, goodness-of-fit testing is not free; you need degrees of freedom. Specifically, you can calculate fit on models where the highest term is <code>{x^(n-2)}</code> where <code>{n}</code> is the number of waves you have. I wanted to show a quadratic fitting process, so I included 4 waves (i.e., x^(4-2) = x^2-order models can be assessed for fit).</p>
<p>It’s good practice to have a set of fit statistcs specified <em>a priori</em> so you aren’t cherry picking good and bad results. Here’s a spread of them I’ve selected, along with ideal levels of fit (commented out).</p>
<pre class="r"><code>selected_fit_stats &lt;-   c(&quot;chisq.scaled&quot;,
                         &quot;df.scaled&quot;, ## must be &gt;0 to test G.O.F.
                         &quot;pvalue.scaled&quot;, ## ideally n.s.
                         &quot;cfi.scaled&quot;, ## ideally ≥ 0.95
                         &quot;rmsea.scaled&quot;, ## ideally ≤ 0.05
                         &quot;rmsea.pvalue.scaled&quot;, ## ideally n.s.
                         &quot;srmr&quot; ## ideally &lt; 0.08
                         )</code></pre>
</div>
<div id="steps-for-a-ppm" class="section level1">
<h1>Steps for a PPM:</h1>
<ol style="list-style-type: decimal">
<li>Plot your data</li>
<li>Assess fit of various models for both variables (i.e., no growth, linear growth, quadratic growth, etc.).</li>
<li>Combine individual ideal models</li>
<li>Assess fit (&amp; modify syntax, typically, but that is nuanced &amp; beyond our scope)</li>
<li>Plot the predicted data &amp; compare to step 1</li>
</ol>
</div>
<div id="step-1.-plot-your-data" class="section level1">
<h1>STEP 1. Plot your data</h1>
<p>This should give you a guess at what forms probably will fit. I did some work in <code>{tidyr}</code> to move the data around, then plotted in <code>{ggplot2}</code>, where we can see individual trajectories for each construct over time.
I set the <code>alpha</code> parameter very low (0.2) so lines are transparent and we can get at density of distribution.</p>
<pre class="r"><code>sim_growth_dat$participant_n &lt;- 1:nrow(sim_growth_dat) #add participant number

x_plot &lt;-
pivot_longer(sim_growth_dat, 
             cols = x1:x4, 
             names_to = &#39;x&#39;,
             names_prefix = &#39;x&#39;)

individual_x_trajectories &lt;- 
  ggplot(x_plot, aes(x = as.numeric(x), y = value, 
                   group = participant_n, 
                   color = participant_n))+
  geom_line(alpha = 0.2) +
  ggtitle(&#39;individual trajectories of x&#39;) +
  xlab(&#39;Timepoint&#39;)+
  ylab(&#39;x&#39;)+
  theme_classic() + xlim(1,4)

individual_x_trajectories</code></pre>
<p><img src="/post/2020-09-08-growth-parallel-process-models_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>You can see that the <code>{x}</code> variable is probably linearly increasing, but a very “shallow” quadratic model might fit better so we should check if it fits well. If both fit well, we will compare them with likelihood ratio tests (LRTs).</p>
<pre class="r"><code>y_plot &lt;-
pivot_longer(sim_growth_dat, 
             cols = y1:y4, 
             names_to = &#39;y&#39;,
             names_prefix = &#39;y&#39;)

individual_y_trajectories &lt;- 
  ggplot(y_plot, aes(x = as.numeric(y), y = value, 
                   group = participant_n, 
                   color = participant_n)) + 
  geom_line(alpha = 0.2) +
  ggtitle(&#39;individual trajectories of y&#39;) +
  xlab(&#39;Timepoint&#39;)+
  ylab(&#39;y&#39;)+
  theme_classic()+xlim(1,4)
individual_y_trajectories</code></pre>
<p><img src="/post/2020-09-08-growth-parallel-process-models_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>It is clear that <code>{y}</code> decreases with time on average, but there is heterogeneity (or variability) in what happens for an individual case. It looks like a either a linear or quadratic model will fit best. </p>
<p>Let’s dive in!</p>
</div>
<div id="step-2.-assess-fit-of-various-models" class="section level1">
<h1>STEP 2. Assess fit of various models</h1>
<p>Time to first fit the model to an intercept-only model (i.e., no growth observed).</p>
<p>Next, we’ll look at linear growth (linear + intercept), then quadratic growth (quadratic + linear + intercept). We won’t go higher than that because we cannot assess fit with only 4 waves.</p>
<p>There are lots of nuances here, but I discuss some common choices here.</p>
<div id="function" class="section level3">
<h3>Function</h3>
<p>The <code>growth()</code> call in <code>{lavaan}</code> is an easy way to specify a growth model. By default, it sets means/intercepts of observed variables to 0 and determines mean structure for latent variables.</p>
</div>
<div id="estimator" class="section level3">
<h3>Estimator</h3>
<p>All data used here is continuous, so we’ll stick with maximum likelihood (<code>estimator = ML</code>) estimation, and I prefer to use the “robust” variant (<code>estimator = MLR</code>) whenever possible to account for non-normal data. </p>
</div>
<div id="missingness" class="section level3">
<h3>Missingness</h3>
<p>For simplicity, there is no missingness in this data. If there were, we could do Little’s Test of Missing data and see patterns of missingness. Assuming data was missing (completely) at random and we didn’t have too much missingness, we could use Full-information Maximum Likelihood to impute missing data. </p>
<pre class="r"><code>int_x_mod &lt;- 
  &#39;
iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4

  &#39;
int_x_fit &lt;- growth(model = int_x_mod,
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat)

int_x_fit_stats&lt;-fitmeasures(int_x_fit, selected_fit_stats) %&gt;% data.frame()
round(int_x_fit_stats, 2)</code></pre>
<pre><code>##                           .
## chisq.scaled        1192.66
## df.scaled              8.00
## pvalue.scaled          0.00
## cfi.scaled             0.02
## rmsea.scaled           0.54
## rmsea.pvalue.scaled    0.00
## srmr                   0.63</code></pre>
<p>The no growth model for <code>{x}</code> does not fit well by any measure. So we’ll move on.</p>
<pre class="r"><code>int_y_mod &lt;- 
  &#39;
iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
  &#39;
int_y_fit &lt;- growth(model = int_y_mod, 
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat)</code></pre>
<pre><code>## Warning in lav_object_post_check(object): lavaan WARNING: some estimated lv
## variances are negative</code></pre>
<pre class="r"><code>int_y_fit_stats&lt;-fitmeasures(int_y_fit, selected_fit_stats) %&gt;% data.frame()
round(int_y_fit_stats, 2)</code></pre>
<pre><code>##                           .
## chisq.scaled        3136.54
## df.scaled              8.00
## pvalue.scaled          0.00
## cfi.scaled             0.00
## rmsea.scaled           0.88
## rmsea.pvalue.scaled    0.00
## srmr                   0.98</code></pre>
<p>The no growth model for <code>{y}</code> does not fit well by any measure either. 
Next, we will check how well a linear-only growth model fits for the <code>{x}</code> &amp; <code>{y}</code> variables</p>
<pre class="r"><code>linear_x_mod &lt;- 
  &#39;
iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4
sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4

  &#39;
linear_x_fit &lt;- growth(model = linear_x_mod,
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat)

linear_x_fit_stats&lt;-fitmeasures(linear_x_fit, selected_fit_stats) %&gt;% data.frame()
round(linear_x_fit_stats, 2)</code></pre>
<pre><code>##                        .
## chisq.scaled        4.03
## df.scaled           5.00
## pvalue.scaled       0.54
## cfi.scaled          1.00
## rmsea.scaled        0.00
## rmsea.pvalue.scaled 0.92
## srmr                0.02</code></pre>
<p>The linear growth model for <code>{x}</code> fits well by all measures. This is what we expected based on the graph of observed data. We should test quadratic models for fit, though.</p>
<pre class="r"><code>linear_y_mod &lt;- 
  &#39;
iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4
  &#39;
linear_y_fit &lt;- growth(model = linear_y_mod,
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat)</code></pre>
<pre><code>## Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov
## variances are negative</code></pre>
<pre class="r"><code>linear_y_fit_stats&lt;-fitmeasures(linear_y_fit, selected_fit_stats) %&gt;% data.frame()
round(linear_y_fit_stats, 2)</code></pre>
<pre><code>##                          .
## chisq.scaled        842.85
## df.scaled             5.00
## pvalue.scaled         0.00
## cfi.scaled            0.61
## rmsea.scaled          0.58
## rmsea.pvalue.scaled   0.00
## srmr                  0.55</code></pre>
<p>Looks like the linear <code>{y}</code> is inadequate across all measures. </p>
<div id="note" class="section level5">
<h5>NOTE:</h5>
<p>Quadratic terms represent the average rate of change of the slope across waves. This is synonymous with acceleration in other disciplines, though this terminology is not often used and ‘quadratic growth’ is typically preferred in SEM.</p>
<pre class="r"><code>quad_x_mod &lt;- 
  &#39;
iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4
sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4
qX =~ 0*x1 + 1*x2 + 4*x3 + 9*x4


  &#39;
quad_x_fit &lt;- growth(model = quad_x_mod, 
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat)</code></pre>
<pre><code>## Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov
## variances are negative</code></pre>
<pre class="r"><code>quad_x_fit_stats &lt;- fitmeasures(quad_x_fit, selected_fit_stats)
round(quad_x_fit_stats, 2)</code></pre>
<pre><code>##        chisq.scaled           df.scaled       pvalue.scaled          cfi.scaled 
##                0.02                1.00                0.89                1.00 
##        rmsea.scaled rmsea.pvalue.scaled                srmr 
##                0.00                0.94                0.00</code></pre>
<p>Here we have an interesting issue, as <code>{x}</code> fits fairly well to both a linear &amp; a quadratic model, but we have a Heywood case, specifically the estimated observed variable variance is negative. Let’s inspect </p>
<pre class="r"><code>lavInspect(quad_x_fit, &quot;est&quot;)$theta</code></pre>
<pre><code>##    x1     x2     x3     x4    
## x1  1.171                     
## x2  0.000  0.718              
## x3  0.000  0.000  1.213       
## x4  0.000  0.000  0.000 -0.064</code></pre>
<p>Our <code>{x4}</code> variable has a negative estimate for the observed variable’s variance. This is a problem, and indicates the model may not represent the data well. There are ways to use parameter constraints to see if the fit is good if we “force” a change to this parameter, but that’s beyond our scope today.</p>
<p>For teaching purposes, we’ll pretend we didn’t have a Heywood case to do the next step.</p>
<p>When you have two well-fitting nested models (in our case linear &amp; quadratic models), we can compare the fit formally with Likelihood Ratio Tests (LRTs). The null hypothesis is essentially that there is no difference in the variance explained by the two models. Parsimony is preferred in a situation where the variance explained is equivalent. </p>
</div>
<div id="note-1" class="section level5">
<h5>NOTE:</h5>
<p>Some will say this test is only valid if the models have n.s. p-values and there are no Heywood cases.</p>
<pre class="r"><code>lavTestLRT(linear_x_fit, quad_x_fit)</code></pre>
<pre><code>## Scaled Chi-Squared Difference Test (method = &quot;satorra.bentler.2001&quot;)
## 
## lavaan NOTE:
##     The &quot;Chisq&quot; column contains standard test statistics, not the
##     robust test that should be reported per model. A robust difference
##     test is a function of two standard (not robust) statistics.
##  
##              Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)
## quad_x_fit    1 7570.4 7625.2 0.0200                              
## linear_x_fit  5 7566.4 7604.3 4.0675     4.0026       4     0.4056</code></pre>
<p>Here, a non-significant p-value tells us that the linear model is preferred here. </p>
<p>Now onto the quadratic <code>{y}</code> model.</p>
<pre class="r"><code>quad_y_mod &lt;- 
  &#39;
iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4
qY =~ 0*y1 + 1*y2 + 4*y3 + 9*y4


  &#39;
quad_y_fit &lt;- growth(model = quad_y_mod, 
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat)

quad_y_fit_stats &lt;- fitmeasures(quad_y_fit, selected_fit_stats)
quad_y_fit_stats</code></pre>
<pre><code>##        chisq.scaled           df.scaled       pvalue.scaled          cfi.scaled 
##               0.190               1.000               0.663               1.000 
##        rmsea.scaled rmsea.pvalue.scaled                srmr 
##               0.000               0.813               0.001</code></pre>
<p>It’s clear that only the <code>{x}</code> linear model was a good one by all fit statistics. We could actually easily see this earlier in Step 1, but it is good that we checked. </p>
<p>When using real—world data this may or may not be the case; I simulated this data specifically to be clean linear and quadratic models for <code>{x}</code> &amp; <code>{y}</code> respectively. </p>
</div>
</div>
</div>
<div id="step-3.-building-the-ppm" class="section level1">
<h1>STEP 3. Building the PPM</h1>
<p>Now that we are fairly confident in functional forms, let’s model them together. </p>
<div id="note-2" class="section level5">
<h5>NOTE:</h5>
<p>For simplicity we are <em>not</em> specifying conditional models which make future growth terms conditional upon earlier growth terms. The distinction between the two is subtle and deserves its own conversation later. For now, just assume growth terms are simply correlated, rather than causally linked.</p>
<pre class="r"><code>full_model &lt;- 
  &#39;
## intercept &amp; slope growth terms for X
iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4
sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4

## intercept, slope, &amp; quadratic terms for Y
iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4
qY =~ 0*y1 + 1*y2 + 4*y3 + 9*y4

## regress growth terms on predictor
qY + iY + sX + iX ~ predictor
sY ~ a1*predictor

## regress outcome on growth terms
outcome ~ iX + sX + iY + b1*sY + qY

## testing indirect effect 
## predictor --&gt; sY --&gt; outcome

predictor_sY_outcome:=a1*b1
  &#39;

full_fit &lt;- growth(model = full_model, 
                     estimator = &#39;MLR&#39;,
                     data = sim_growth_dat)
full_fit_stats &lt;- fitmeasures(full_fit, selected_fit_stats)
round(full_fit_stats,2) </code></pre>
<pre><code>##        chisq.scaled           df.scaled       pvalue.scaled          cfi.scaled 
##               28.23               34.00                0.75                1.00 
##        rmsea.scaled rmsea.pvalue.scaled                srmr 
##                0.00                1.00                0.03</code></pre>
</div>
</div>
<div id="full-model-fit" class="section level1">
<h1>Full Model Fit</h1>
<p>We can see that this model fits well across all fit statistics chosen. This model is deemed acceptable and we can now interpret the model results</p>
<pre class="r"><code>summary(full_fit,
        stand = T,
        rsq = T)</code></pre>
<pre><code>## lavaan 0.6-7.1577 ended normally after 65 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of free parameters                         29
##                                                       
##   Number of observations                           500
##                                                       
## Model Test User Model:
##                                                Standard      Robust
##   Test Statistic                                 28.456      28.233
##   Degrees of freedom                                 34          34
##   P-value (Chi-square)                            0.736       0.746
##   Scaling correction factor                                   1.008
##        Yuan-Bentler correction (Mplus variant)                     
## 
## Parameter Estimates:
## 
##   Standard errors                             Sandwich
##   Information bread                           Observed
##   Observed information based on                Hessian
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   iX =~                                                                 
##     x1                1.000                               1.023    0.704
##     x2                1.000                               1.023    0.588
##     x3                1.000                               1.023    0.404
##     x4                1.000                               1.023    0.295
##   sX =~                                                                 
##     x1                0.000                               0.000    0.000
##     x2                1.000                               1.046    0.601
##     x3                2.000                               2.092    0.826
##     x4                3.000                               3.138    0.905
##   iY =~                                                                 
##     y1                1.000                               1.020    0.721
##     y2                1.000                               1.020    0.350
##     y3                1.000                               1.020    0.161
##     y4                1.000                               1.020    0.089
##   sY =~                                                                 
##     y1                0.000                               0.000    0.000
##     y2                1.000                               2.312    0.793
##     y3                2.000                               4.624    0.732
##     y4                3.000                               6.936    0.604
##   qY =~                                                                 
##     y1                0.000                               0.000    0.000
##     y2                1.000                               0.964    0.331
##     y3                4.000                               3.855    0.610
##     y4                9.000                               8.674    0.755
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   qY ~                                                                  
##     predictor         0.041    0.048    0.850    0.395    0.042    0.043
##   iY ~                                                                  
##     predictor         0.034    0.060    0.564    0.573    0.033    0.034
##   sX ~                                                                  
##     predictor         0.008    0.051    0.161    0.872    0.008    0.008
##   iX ~                                                                  
##     predictor         0.067    0.060    1.119    0.263    0.065    0.066
##   sY ~                                                                  
##     predictor (a1)    2.022    0.079   25.545    0.000    0.874    0.888
##   outcome ~                                                             
##     iX                1.994    0.145   13.755    0.000    2.040    0.278
##     sX               -0.017    0.146   -0.115    0.908   -0.018   -0.002
##     iY               -0.028    0.186   -0.149    0.881   -0.028   -0.004
##     sY        (b1)    2.973    0.104   28.596    0.000    6.874    0.937
##     qY               -0.242    0.161   -1.510    0.131   -0.234   -0.032
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .x1                0.000                               0.000    0.000
##    .x2                0.000                               0.000    0.000
##    .x3                0.000                               0.000    0.000
##    .x4                0.000                               0.000    0.000
##    .y1                0.000                               0.000    0.000
##    .y2                0.000                               0.000    0.000
##    .y3                0.000                               0.000    0.000
##    .y4                0.000                               0.000    0.000
##    .outcome           0.000                               0.000    0.000
##    .iX                1.976    0.059   33.700    0.000    1.931    1.931
##    .sX                0.991    0.051   19.350    0.000    0.948    0.948
##    .iY                0.031    0.061    0.508    0.611    0.030    0.030
##    .sY               -1.153    0.082  -14.019    0.000   -0.499   -0.499
##    .qY               -1.548    0.048  -32.151    0.000   -1.607   -1.607
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .x1                1.067    0.099   10.777    0.000    1.067    0.505
##    .x2                0.885    0.069   12.924    0.000    0.885    0.292
##    .x3                0.983    0.104    9.492    0.000    0.983    0.153
##    .x4                1.113    0.197    5.646    0.000    1.113    0.093
##    .y1                0.961    0.107    8.991    0.000    0.961    0.480
##    .y2                0.868    0.083   10.470    0.000    0.868    0.102
##    .y3                0.996    0.179    5.557    0.000    0.996    0.025
##    .y4                2.467    0.949    2.601    0.009    2.467    0.019
##    .outcome           0.814    0.927    0.878    0.380    0.814    0.015
##    .iX                1.043    0.100   10.444    0.000    0.996    0.996
##    .sX                1.094    0.076   14.393    0.000    1.000    1.000
##    .iY                1.040    0.108    9.595    0.000    0.999    0.999
##    .sY                1.131    0.125    9.078    0.000    0.212    0.212
##    .qY                0.927    0.068   13.684    0.000    0.998    0.998
## 
## R-Square:
##                    Estimate
##     x1                0.495
##     x2                0.708
##     x3                0.847
##     x4                0.907
##     y1                0.520
##     y2                0.898
##     y3                0.975
##     y4                0.981
##     outcome           0.985
##     iX                0.004
##     sX                0.000
##     iY                0.001
##     sY                0.788
##     qY                0.002
## 
## Defined Parameters:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##     predctr_sY_tcm    6.011    0.159   37.874    0.000    6.011    0.832</code></pre>
</div>
<div id="interpretation" class="section level1">
<h1>Interpretation</h1>
<p>I am going to trust you understand how to read <code>{lavaan}</code> here, so I’m not going to walk through this line by line. The headlines are <code>{iX}</code> &amp; <code>{sY}</code> significantly predict <code>{outcome}</code>, with the latter predicting it to a much larger degree than the former. </p>
<p>This means baseline levels of <code>{x}</code> predict outcome, as does the linear rate of change of <code>{y}</code>, both positively such that higher levels of initial <code>{x}</code> or faster rates of change in <code>{y}</code> lead to higher levels of <code>{outcome}</code>.</p>
<p>In our example, I included a time-invariant covariate <code>{predictor}</code>. Since <code>{predictor}</code> significantly predicted <code>{sY}</code> and <code>{sY}</code> predicted <code>{outcome}</code>, we would want to look for mediation. You may trust the estimate given by simply the product of each coefficient and it’s significance test, but it is better to rely on other methods to test indirect effects.</p>
</div>
<div id="bootstrapping" class="section level1">
<h1>Bootstrapping</h1>
<p>Bootstrapping is a resampling method (with replacement) that is appreciated for building confidence intervals around parameter estimates of indirect effects, at least in part, because they do not make distributional assumptions about the indirect effect. This creates a more reliable test than standard significance tests. A quick Google Scholar search can inform you on this topic more deeply than this post, but I used this to test the indirect effects using 5000 simulated data sets.</p>
<pre class="r"><code>final_fit_boot&lt;- growth(full_fit, data = sim_growth_dat, estimator = &quot;ML&quot;,
                        meanstructure = T,
                        se = &quot;bootstrap&quot;,
                        bootstrap = 5000,
                        parallel = &quot;multicore&quot;)

parameterEstimates(final_fit_boot,
                   level = .95,
                   boot.ci.type = &quot;bca.simple&quot;,
                   stand = T)[61,c(4,5,9,10)]</code></pre>
<pre><code>##                   label   est ci.lower ci.upper
## 61 predictor_sY_outcome 6.011    5.707    6.335</code></pre>
<p>The model converged nearly every time without issue. Of our 5000 bootstrap draws, only 7 were not successful; this is not shown here, but is if you call <code>{summary(full_fit, fit = T)}</code>, which I didn’t do for brevity. </p>
<p>Furthermore, looking at the 95% confidence intervals, we find the same result as we did regarding the indirect effect as without bootstrapping. These are the results I trust more, especially since we used <code>bca.simple</code>. </p>
<p>Most likely this is what we wanted to do with this model (at least in my field). Assess if a predictor influences growth in a construct, then see if there is an indirect effect (and quanitify its magnitude).</p>
<div id="note-3" class="section level5">
<h5>NOTE:</h5>
<p>I made it so only the label, unstandardized estimate and confidence intervals showed up with the <code>[61,c(4,5,9,10)]</code> portion of code, but you should <em>not</em> trust the p-values from this parameterEstimates() if you go with <em>anything but the default</em> (i.e., <code>boot.ci.type = norm</code>). 
This is because the p-value is built assuming a normal distribution; this eliminates some of the benefits of bootstrapping gained by <code>bca.simple</code> and other methods, but gives you a p-value, which matters a lot to some.</p>
</div>
</div>
<div id="plotting" class="section level1">
<h1>Plotting</h1>
<p>We can plot the growth of these traits, as well with <code>{ggplot2}</code>, which helps verify you did this correctly. I won’t go into it here, but these plots can be modified with facet wrapping and other grouping/coloring methods to see how different groups have different slopes, for example. </p>
<p>First we extract factor scores &amp; save this as a data frame, then we can plot.
For a linear model, this is pretty simple:</p>
<pre class="r"><code>plot_dat &lt;- lavPredict(full_fit) %&gt;% data.frame()
plot_dat$participant_n &lt;- 1:nrow(plot_dat)
plot_dat$predictor &lt;- sim_growth_dat$predictor


predicted_x_trajectories &lt;- ggplot(data=plot_dat) +
scale_x_continuous(name = &quot;Timepoint&quot;,
                 limits=c(0, 3),
                 breaks = c(0, 1, 2, 3),
                 labels = c(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;)
                 ) +
scale_y_continuous(name = &quot;x&quot;,
                 limits=c(-5,15)
                 )+
  geom_abline(data=plot_dat, 
              mapping=aes(slope=sX, 
                          intercept=iX, 
                          color = participant_n),
              alpha = 0.2) + 
  theme_classic() + ggtitle(&#39;predicted x trajectories&#39;) </code></pre>
<p>With this call, I can stack the actual and predicted trajectory graphs:</p>
<pre class="r"><code>gridExtra::grid.arrange(individual_x_trajectories, predicted_x_trajectories, ncol=1)</code></pre>
<p><img src="/post/2020-09-08-growth-parallel-process-models_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>For a quadratic model, this is more challenging, but here’s some code to do it:</p>
<pre class="r"><code>plot_dat &lt;- lavPredict(full_fit) %&gt;% data.frame()
plot_dat$participant_n &lt;- 1:nrow(plot_dat)
plot_dat$predictor &lt;- sim_growth_dat$predictor

qY &lt;- plot_dat$qY
sY &lt;- plot_dat$sY
iY &lt;- plot_dat$iY

test &lt;- function(y) {qY*y ^ 2 + sY*y + iY}


plot_dat_2&lt;-data.frame(`T1` = test(0), 
                       `T2` = test(1), 
                       `T3` = test(2), 
                       `T4` = test(3), 
                       row.names = 1:nrow(plot_dat))

names(plot_dat) &lt;- c(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;) 

test0 &lt;-test(0)
test1&lt;-test(1)
test2&lt;-test(2)
test3&lt;-test(3)

Y_df &lt;- matrix(c(test0, 
                 test1, 
                 test2, 
                 test3), 
               ncol = 1)

df_long_wave &lt;- matrix(c(rep(1,500), 
                        rep(2, 500),
                        rep(3, 500), 
                        rep(4, 500)), 
                      ncol = 1)


plot_dat_2 &lt;- data.frame(
  participant_n = matrix(
    rep(1:500,4), ncol = 1),
  Timepoint = df_long_wave,
  y = Y_df)

predicted_y_trajectories &lt;- plot_dat_2 %&gt;% ggplot(aes(x = Timepoint, 
                          y = y, 
                          group = participant_n, 
                          color = participant_n), 
                          alpha = 0.2) +
 geom_smooth(formula = y ~ x + I(x^2), 
             method = &quot;lm&quot;, se = F)+
  theme_classic() + ggtitle(&#39;predicted trajectories of y&#39;)</code></pre>
<p>Again, let’s stack the actual and predicted trajectory graphs:</p>
<pre class="r"><code>gridExtra::grid.arrange(individual_y_trajectories, predicted_y_trajectories, ncol=1)</code></pre>
<p><img src="/post/2020-09-08-growth-parallel-process-models_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
</div>
<div id="next-steps" class="section level1">
<h1>Next Steps:</h1>
<p>If you were to be working on this, I would work further to make the model more parsimoneous, as well as seeing if alternate modifications would increase model fit.
Ways to do this include, but are not limited to, constraining residuals, assessing the role of the predictor on the observed vs. manifest model, making the growth terms conditional upon earlier terms, etc.</p>
</div>
<div id="looking-at-the-simulation-call" class="section level1">
<h1>Looking at the simulation call</h1>
<p>Here is the exact simulation call I did in case anyone is curious. I wanted the data to be interesting, so I made sure to set some things (e.g., variances, latent means/intercepts, relationships between variables, etc.)</p>
<pre class="r"><code>growth_mod &lt;- 
  &#39;

## intercept &amp; slope growth terms for X
iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4
sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4

## intercept, slope, &amp; quadratic terms for Y
iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4
sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4
qY =~ 0*y1 + 1*y2 + 4*y3 + 9*y4

## set variances 

y4 ~~ 2*y4
x4 ~~ 1*x4

## set latent means/intercepts
iX ~ 2*1
sX ~ 1*1
sY ~ -1*1
qY ~ -1.5*1

sY ~ 2*predictor

outcome ~ 2*iX + 3*sY 
  &#39;</code></pre>
<p>In the data I simulated, Variable <code>{x}</code> is changing linearly over time and variable <code>{y}</code> is changing quadratically, which his what we found.</p>
<pre class="r"><code>sim_growth_dat &lt;- simulateData(model = growth_mod, 
                               model.type = &quot;growth&quot;, 
                               seed = 82020, 
                               orthogonal = F,
                               auto.cov.y = T, 
                               auto.var = T
                               )</code></pre>
</div>

  
  <h4><i class="fa-share-alt" aria-hidden="true"></i>&nbsp;Share!</h4>
<ul class="share-buttons">
	<li><a href="https://www.facebook.com/sharer/sharer.php?u=%2fpost%2fgrowth-parallel-process-models%2f" target="_blank" title="Share on Facebook"><i class="fa-facebook" aria-hidden="true"></i><span class="sr-only">Share on Facebook</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="https://twitter.com/intent/tweet?source=%2fpost%2fgrowth-parallel-process-models%2f&via=HorribleGeek" target="_blank" title="Tweet"><i class="fa-twitter" aria-hidden="true"></i><span class="sr-only">Tweet</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="https://plus.google.com/share?url=%2fpost%2fgrowth-parallel-process-models%2f" target="_blank" title="Share on Google+"><i class="fa-google-plus" aria-hidden="true"></i><span class="sr-only">Share on Google+</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="http://www.tumblr.com/share?v=3&u=%2fpost%2fgrowth-parallel-process-models%2f" target="_blank" title="Post to Tumblr"><i class="fa-tumblr" aria-hidden="true"></i><span class="sr-only">Post to Tumblr</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="http://pinterest.com/pin/create/button/?url=%2fpost%2fgrowth-parallel-process-models%2f" target="_blank" title="Pin it"><i class="fa-pinterest-p" aria-hidden="true"></i><span class="sr-only">Pin it</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="http://www.reddit.com/submit?url=%2fpost%2fgrowth-parallel-process-models%2f" target="_blank" title="Submit to Reddit"><i class="fa-reddit-alien" aria-hidden="true"></i><span class="sr-only">Submit to Reddit</span></a>
	</li>
</ul>


<style>
	ul.share-buttons{
	  list-style: none;
	  padding: 0;
	}

	ul.share-buttons li{
	  display: inline;
	}

	ul.share-buttons .sr-only{
	  position: absolute;
	  clip: rect(1px 1px 1px 1px);
	  clip: rect(1px, 1px, 1px, 1px);
	  padding: 0;
	  border: 0;
	  height: 1px;
	  width: 1px;
	  overflow: hidden;
	}
</style>


  
<div class="prev-next-post pure-g">
  <div class="pure-u-1-24" style="text-align: left;">
    
    <a href="/post/decision_trees_in_r/"><i class="fa fa-chevron-left"></i></a>
    
  </div>
  <div class="pure-u-10-24">
    
    <nav class="prev">
      <a href="/post/decision_trees_in_r/">Tidymodels: Decision Tree Learning in R</a>
    </nav>
    
  </div>
  <div class="pure-u-2-24">
    &nbsp;
  </div>
  <div class="pure-u-10-24">
    
  </div>
  <div class="pure-u-1-24" style="text-align: right;">
    
  </div>
</div>



  
<div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = 'Your Disqus shortname';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


</div>

</div>
</div>
<script src="/js/ui.js"></script>
<script src="/js/menus.js"></script>


<script>
  
  if (window.location.hostname != "localhost") {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'Your Google Analytics tracking ID', 'auto');
    ga('send', 'pageview');
  }
</script>





<script src="/js/math-code.js"></script>
  <script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  


</body>
</html>

